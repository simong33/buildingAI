{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from app.ml_logic.preprocess import preprocess\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/dpe.csv')\n",
    "df = df.dropna(subset=['classe_bilan_dpe'])\n",
    "target = df['classe_bilan_dpe']\n",
    "df = df.drop(['classe_bilan_dpe', 'batiment_groupe_id',], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == type(object):\n",
    "        if df[column].str.isnumeric().all():\n",
    "            df[column] = pd.to_numeric(df[column])\n",
    "        else:\n",
    "            try:\n",
    "                df[column] = df[column].astype(float)\n",
    "            except ValueError:\n",
    "                df[column] = df[column].astype(str)\n",
    "                le = LabelEncoder()\n",
    "                df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "scaler = StandardScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDLING MISSING VALUES \n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df = pd.DataFrame(imputer.fit_transform(df), columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and trainning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "## Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30,],\n",
    "    'n_estimators': [100, 200, 300,]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=100, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "## Encoding target variable using OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "y_train = ordinal_encoder.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test = ordinal_encoder.transform(np.array(y_test).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Flavien.PICTET/.pyenv/versions/3.10.6/envs/buildingAI/lib/python3.10/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 9 is smaller than n_iter=100. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................max_depth=10, n_estimators=100; total time= 1.3min\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time= 1.3min\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time= 1.3min\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time= 1.3min\n",
      "[CV] END .....................max_depth=10, n_estimators=100; total time= 1.3min\n",
      "[CV] END .....................max_depth=10, n_estimators=200; total time= 2.6min\n",
      "[CV] END .....................max_depth=10, n_estimators=200; total time= 2.6min\n",
      "[CV] END .....................max_depth=10, n_estimators=200; total time= 2.6min\n",
      "[CV] END .....................max_depth=10, n_estimators=200; total time= 2.6min\n",
      "[CV] END .....................max_depth=10, n_estimators=200; total time= 2.6min\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time= 2.2min\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time= 2.2min\n",
      "[CV] END .....................max_depth=10, n_estimators=300; total time= 4.0min\n",
      "[CV] END .....................max_depth=10, n_estimators=300; total time= 4.0min\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time= 2.2min\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time= 2.2min\n",
      "[CV] END .....................max_depth=20, n_estimators=100; total time= 2.2min\n",
      "[CV] END .....................max_depth=10, n_estimators=300; total time= 3.9min\n",
      "[CV] END .....................max_depth=10, n_estimators=300; total time= 3.9min\n",
      "[CV] END .....................max_depth=10, n_estimators=300; total time= 3.9min\n",
      "[CV] END .....................max_depth=20, n_estimators=200; total time= 4.4min\n",
      "[CV] END .....................max_depth=20, n_estimators=200; total time= 4.5min\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time= 2.6min\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time= 2.6min\n",
      "[CV] END .....................max_depth=20, n_estimators=200; total time= 4.4min\n",
      "[CV] END .....................max_depth=20, n_estimators=200; total time= 4.4min\n",
      "[CV] END .....................max_depth=20, n_estimators=200; total time= 4.4min\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time= 2.6min\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time= 2.6min\n",
      "[CV] END .....................max_depth=30, n_estimators=100; total time= 2.7min\n",
      "[CV] END .....................max_depth=20, n_estimators=300; total time= 6.8min\n",
      "[CV] END .....................max_depth=20, n_estimators=300; total time= 6.9min\n",
      "[CV] END .....................max_depth=20, n_estimators=300; total time= 6.9min\n",
      "[CV] END .....................max_depth=20, n_estimators=300; total time= 6.9min\n",
      "[CV] END .....................max_depth=20, n_estimators=300; total time= 6.9min\n",
      "[CV] END .....................max_depth=30, n_estimators=200; total time= 5.6min\n",
      "[CV] END .....................max_depth=30, n_estimators=200; total time= 5.5min\n",
      "[CV] END .....................max_depth=30, n_estimators=200; total time= 5.5min\n",
      "[CV] END .....................max_depth=30, n_estimators=200; total time= 5.4min\n",
      "[CV] END .....................max_depth=30, n_estimators=200; total time= 5.3min\n",
      "[CV] END .....................max_depth=30, n_estimators=300; total time= 7.7min\n",
      "[CV] END .....................max_depth=30, n_estimators=300; total time= 7.5min\n",
      "[CV] END .....................max_depth=30, n_estimators=300; total time= 7.4min\n",
      "[CV] END .....................max_depth=30, n_estimators=300; total time= 7.0min\n",
      "[CV] END .....................max_depth=30, n_estimators=300; total time= 7.0min\n",
      "Accuracy: 0.40810433610857116\n",
      "Precision: 0.41320463513341427\n",
      "Recall: 0.40810433610857116\n",
      "F1 Score: 0.377804410342353\n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "## Training the model\n",
    "random_search.fit(X_train, y_train.ravel())\n",
    "\n",
    "## Making predictions\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "## Evaluating the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "## Print the best parameters from the Randomized Search\n",
    "print(\"Best Parameters:\", random_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buildingAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
